{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed0ad40-3caa-434c-baa2-ae25cbd810a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"query_id\": \"fe810f97-5471-4403-9a3a-ef158c27f10c\",\n",
      "    \"result_type\": \"entry\",\n",
      "    \"total_count\": 10,\n",
      "    \"result_set\": [\n",
      "        {\n",
      "            \"identifier\": \"3ONA\",\n",
      "            \"score\": 1.0\n",
      "        },\n",
      "        {\n",
      "            \"identifier\": \"4XT3\",\n",
      "            \"score\": 1.0\n",
      "        },\n",
      "        {\n",
      "            \"identifier\": \"7RKF\",\n",
      "            \"score\": 1.0\n",
      "        },\n",
      "        {\n",
      "            \"identifier\": \"7RKM\",\n",
      "            \"score\": 1.0\n",
      "        },\n",
      "        {\n",
      "            \"identifier\": \"7RKN\",\n",
      "            \"score\": 1.0\n",
      "        },\n",
      "        {\n",
      "            \"identifier\": \"1B2T\",\n",
      "            \"score\": 0.9090909090909091\n",
      "        },\n",
      "        {\n",
      "            \"identifier\": \"4XT1\",\n",
      "            \"score\": 0.8636363636363636\n",
      "        },\n",
      "        {\n",
      "            \"identifier\": \"1F2L\",\n",
      "            \"score\": 0.8181818181818182\n",
      "        },\n",
      "        {\n",
      "            \"identifier\": \"7XBX\",\n",
      "            \"score\": 0.7272727272727273\n",
      "        },\n",
      "        {\n",
      "            \"identifier\": \"5WB2\",\n",
      "            \"score\": 0.0\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Function to retrieve canonical sequence from UniProt by UniProt ID\n",
    "def get_canonical_sequence(uniprot_id):\n",
    "    url = f\"https://www.uniprot.org/uniprot/{uniprot_id}.fasta\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        fasta_data = response.text\n",
    "        # Extract sequence from FASTA format (skip the header line starting with '>')\n",
    "        sequence = ''.join(fasta_data.split('\\n')[1:])\n",
    "        return sequence\n",
    "    else:\n",
    "        print(f\"Failed to retrieve sequence for UniProt ID: {uniprot_id}\")\n",
    "        return None\n",
    "\n",
    "# Function to create the PDB search query\n",
    "def create_pdb_blast_query(sequences, evalue_cutoff=0.001, identity_cutoff=0.7):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"type\": \"group\",\n",
    "            \"logical_operator\": \"or\",\n",
    "            \"nodes\": []\n",
    "        },\n",
    "        \"request_options\": {\n",
    "            \"scoring_strategy\": \"sequence\",\n",
    "            \"paginate\": {\n",
    "                \"start\": 0,\n",
    "                \"rows\": 100\n",
    "            }\n",
    "        },\n",
    "        \"return_type\": \"entry\"\n",
    "    }\n",
    "    \n",
    "    # Add each sequence to the query\n",
    "    for seq in sequences:\n",
    "        node = {\n",
    "            \"type\": \"terminal\",\n",
    "            \"service\": \"sequence\",\n",
    "            \"parameters\": {\n",
    "                \"evalue_cutoff\": evalue_cutoff,\n",
    "                \"identity_cutoff\": identity_cutoff,\n",
    "                \"sequence_type\": \"protein\",\n",
    "                \"value\": seq\n",
    "            }\n",
    "        }\n",
    "        query[\"query\"][\"nodes\"].append(node)\n",
    "    \n",
    "    return query\n",
    "\n",
    "# Function to perform PDB BLAST search\n",
    "def perform_pdb_blast_search(query):\n",
    "    url = \"https://search.rcsb.org/rcsbsearch/v2/query?json\"  # RCSB PDB search endpoint\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(query))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Returns the results in JSON format\n",
    "    else:\n",
    "        print(f\"Failed to perform PDB search. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to read UniProt IDs from a file\n",
    "def read_uniprot_ids_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            # Read all lines, strip any excess whitespace, and filter out empty lines\n",
    "            return [line.strip() for line in file.readlines() if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' not found.\")\n",
    "        return []\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # File path to the txt file containing UniProt IDs (one per line)\n",
    "    uniprot_file = \"uniprot_ids_test.txt\"\n",
    "\n",
    "    # Read UniProt IDs from the file\n",
    "    uniprot_ids = read_uniprot_ids_from_file(uniprot_file)\n",
    "\n",
    "    if not uniprot_ids:\n",
    "        print(\"No UniProt IDs found in the file.\")\n",
    "        return\n",
    "\n",
    "    # Print the number of UniProt IDs used\n",
    "    print(f\"Number of UniProt IDs used: {len(uniprot_ids)}\")\n",
    "    \n",
    "    # Retrieve sequences for each UniProt ID\n",
    "    sequences = []\n",
    "    for uniprot_id in uniprot_ids:\n",
    "        sequence = get_canonical_sequence(uniprot_id)\n",
    "        if sequence:\n",
    "            sequences.append(sequence)\n",
    "\n",
    "    if sequences:\n",
    "        # Create PDB BLAST search query\n",
    "        pdb_query = create_pdb_blast_query(sequences)\n",
    "\n",
    "        # Perform PDB BLAST search\n",
    "        results = perform_pdb_blast_search(pdb_query)\n",
    "\n",
    "        if results:\n",
    "            # Handle results (print, save, etc.)\n",
    "            print(json.dumps(results, indent=4))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df2b207-11de-4cb5-99bf-b29c2ae7db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UniProt IDs used: 46\n",
      "    identifier\n",
      "0         3KBX\n",
      "1         2X69\n",
      "2         3H44\n",
      "3         5COR\n",
      "4         5D65\n",
      "..         ...\n",
      "227       3GV3\n",
      "228       8K3Z\n",
      "229       4LMQ\n",
      "230       5IZB\n",
      "231       5L7M\n",
      "\n",
      "[232 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Function to retrieve canonical sequence from UniProt by UniProt ID\n",
    "def get_canonical_sequence(uniprot_id):\n",
    "    url = f\"https://www.uniprot.org/uniprot/{uniprot_id}.fasta\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        fasta_data = response.text\n",
    "        # Extract sequence from FASTA format (skip the header line starting with '>')\n",
    "        sequence = ''.join(fasta_data.split('\\n')[1:])\n",
    "        return sequence\n",
    "    else:\n",
    "        print(f\"Failed to retrieve sequence for UniProt ID: {uniprot_id}\")\n",
    "        return None\n",
    "\n",
    "# Function to create the PDB search query\n",
    "def create_pdb_blast_query(sequences, evalue_cutoff=0.01, identity_cutoff=0.5):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"type\": \"group\",\n",
    "            \"logical_operator\": \"or\",\n",
    "            \"nodes\": []\n",
    "        },\n",
    "        \"request_options\": {\n",
    "            \"scoring_strategy\": \"sequence\",\n",
    "            \"paginate\": {\n",
    "                \"start\": 0,\n",
    "                \"rows\": 500\n",
    "            }\n",
    "        },\n",
    "        \"return_type\": \"entry\"\n",
    "    }\n",
    "    \n",
    "    # Add each sequence to the query\n",
    "    for seq in sequences:\n",
    "        node = {\n",
    "            \"type\": \"terminal\",\n",
    "            \"service\": \"sequence\",\n",
    "            \"parameters\": {\n",
    "                \"evalue_cutoff\": evalue_cutoff,\n",
    "                #\"identity_cutoff\": identity_cutoff,\n",
    "                \"sequence_type\": \"protein\",\n",
    "                \"value\": seq\n",
    "            }\n",
    "        }\n",
    "        query[\"query\"][\"nodes\"].append(node)\n",
    "    \n",
    "    return query\n",
    "\n",
    "# Function to perform PDB BLAST search\n",
    "def perform_pdb_blast_search(query):\n",
    "    url = \"https://search.rcsb.org/rcsbsearch/v2/query?json\"  # RCSB PDB search endpoint\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(query))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Returns the results in JSON format\n",
    "    else:\n",
    "        print(f\"Failed to perform PDB search. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to read UniProt IDs from a file\n",
    "def read_uniprot_ids_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            # Read all lines, strip any excess whitespace, and filter out empty lines\n",
    "            return [line.strip() for line in file.readlines() if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' not found.\")\n",
    "        return []\n",
    "\n",
    "# Function to process results into a pandas DataFrame\n",
    "def process_results_to_dataframe(results):\n",
    "    if \"result_set\" in results:\n",
    "        # Extract 'identifier' and 'score' from each result in result_set\n",
    "        data = [{\"identifier\": entry[\"identifier\"]} for entry in results[\"result_set\"]]\n",
    "        # Create a DataFrame from the extracted data\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv('pdb_blast_results.csv', index=False)  # To save as CSV\n",
    "\n",
    "        # Display the DataFrame as a table\n",
    "        print(df)\n",
    "    else:\n",
    "        print(\"No results found in the response.\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # File path to the txt file containing UniProt IDs (one per line)\n",
    "    uniprot_file = \"uniprot_ids_human.txt\"\n",
    "\n",
    "    # Read UniProt IDs from the file\n",
    "    uniprot_ids = read_uniprot_ids_from_file(uniprot_file)\n",
    "\n",
    "    if not uniprot_ids:\n",
    "        print(\"No UniProt IDs found in the file.\")\n",
    "        return\n",
    "\n",
    "    # Print the number of UniProt IDs used\n",
    "    print(f\"Number of UniProt IDs used: {len(uniprot_ids)}\")\n",
    "    \n",
    "    # Retrieve sequences for each UniProt ID\n",
    "    sequences = []\n",
    "    for uniprot_id in uniprot_ids:\n",
    "        sequence = get_canonical_sequence(uniprot_id)\n",
    "        if sequence:\n",
    "            sequences.append(sequence)\n",
    "\n",
    "    if sequences:\n",
    "        # Create PDB BLAST search query\n",
    "        pdb_query = create_pdb_blast_query(sequences)\n",
    "\n",
    "        # Perform PDB BLAST search\n",
    "        results = perform_pdb_blast_search(pdb_query)\n",
    "\n",
    "        if results:\n",
    "            # Process results into a pandas DataFrame\n",
    "            process_results_to_dataframe(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d3d8b1-5354-4543-910e-5d1b18a4b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PDB IDs fetched: 247\n",
      "PDB IDs have been saved to 'pdb_ids.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "def fetch_pdb_ids_by_pfam(pfam_accession):\n",
    "    \"\"\"\n",
    "    Fetches PDB IDs associated with a given PFAM accession number.\n",
    "\n",
    "    Parameters:\n",
    "    - pfam_accession: PFAM accession number as a string.\n",
    "\n",
    "    Returns:\n",
    "    - A list of PDB IDs.\n",
    "    \"\"\"\n",
    "    # Define the base URL for the PDBe search API\n",
    "    url = \"https://www.ebi.ac.uk/pdbe/search/pdb/select\"\n",
    "    \n",
    "    # Define the search query and parameters\n",
    "    query = f\"pfam_accession:{pfam_accession}\"\n",
    "    params = {\n",
    "        'q': query,    # Query parameter\n",
    "        'wt': 'json',  # Requesting JSON format\n",
    "        'rows': 1000   # Maximum number of rows (increase if needed)\n",
    "    }\n",
    "    \n",
    "    # Send a GET request to the PDBe search API\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract and return PDB IDs from the \"docs\" field\n",
    "        return [doc.get('pdb_id') for doc in data['response']['docs'] if doc.get('pdb_id')]\n",
    "    else:\n",
    "        # Handle errors\n",
    "        print(f\"Failed to fetch data from PDBe API. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def save_pdb_ids_to_csv(pdb_ids, filename='pdb_ids.csv'):\n",
    "    \"\"\"\n",
    "    Saves a list of PDB IDs to a CSV file in sorted order.\n",
    "\n",
    "    Parameters:\n",
    "    - pdb_ids: List of PDB IDs.\n",
    "    - filename: Name of the CSV file (default is 'pdb_ids.csv').\n",
    "    \"\"\"\n",
    "    # Sort the PDB IDs\n",
    "    sorted_pdb_ids = sorted(pdb_ids)\n",
    "\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for pdb_id in sorted_pdb_ids:\n",
    "            writer.writerow([pdb_id])  # Write each PDB ID\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "pfam_accession = \"PF00048\"\n",
    "pdb_ids = fetch_pdb_ids_by_pfam(pfam_accession)\n",
    "\n",
    "# Print the number of fetched PDB IDs\n",
    "print(f\"Number of PDB IDs fetched: {len(pdb_ids)}\")\n",
    "\n",
    "# Save the PDB IDs to a CSV file\n",
    "save_pdb_ids_to_csv(pdb_ids)\n",
    "\n",
    "# Inform the user\n",
    "print(f\"PDB IDs have been saved to 'pdb_ids.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad22e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique PDB IDs found: 247\n",
      "Combined PDB IDs have been saved to 'pdb_ids.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Function to retrieve canonical sequence from UniProt by UniProt ID\n",
    "def get_canonical_sequence(uniprot_id):\n",
    "    url = f\"https://www.uniprot.org/uniprot/{uniprot_id}.fasta\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        fasta_data = response.text\n",
    "        sequence = ''.join(fasta_data.split('\\n')[1:])  # Skip the header line\n",
    "        return sequence\n",
    "    else:\n",
    "        print(f\"Failed to retrieve sequence for UniProt ID: {uniprot_id}\")\n",
    "        return None\n",
    "\n",
    "# Function to create the PDB search query\n",
    "def create_pdb_blast_query(sequences, evalue_cutoff=0.01):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"type\": \"group\",\n",
    "            \"logical_operator\": \"or\",\n",
    "            \"nodes\": []\n",
    "        },\n",
    "        \"request_options\": {\n",
    "            \"scoring_strategy\": \"sequence\",\n",
    "            \"paginate\": {\n",
    "                \"start\": 0,\n",
    "                \"rows\": 500\n",
    "            }\n",
    "        },\n",
    "        \"return_type\": \"entry\"\n",
    "    }\n",
    "\n",
    "    for seq in sequences:\n",
    "        node = {\n",
    "            \"type\": \"terminal\",\n",
    "            \"service\": \"sequence\",\n",
    "            \"parameters\": {\n",
    "                \"evalue_cutoff\": evalue_cutoff,\n",
    "                \"sequence_type\": \"protein\",\n",
    "                \"value\": seq\n",
    "            }\n",
    "        }\n",
    "        query[\"query\"][\"nodes\"].append(node)\n",
    "\n",
    "    return query\n",
    "\n",
    "# Function to perform PDB BLAST search\n",
    "def perform_pdb_blast_search(query):\n",
    "    url = \"https://search.rcsb.org/rcsbsearch/v2/query?json\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(query))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to perform PDB search. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to fetch PDB IDs associated with a PFAM accession\n",
    "def fetch_pdb_ids_by_pfam(pfam_accession):\n",
    "    url = \"https://www.ebi.ac.uk/pdbe/search/pdb/select\"\n",
    "    query = f\"pfam_accession:{pfam_accession}\"\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'wt': 'json',\n",
    "        'rows': 1000\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return [doc.get('pdb_id').lower() for doc in data['response']['docs'] if doc.get('pdb_id')]\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from PDBe API. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Function to read UniProt IDs from a file\n",
    "def read_uniprot_ids_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            return [line.strip() for line in file.readlines() if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' not found.\")\n",
    "        return []\n",
    "\n",
    "# Function to process results and extract unique PDB IDs\n",
    "def extract_pdb_ids_from_results(results):\n",
    "    if \"result_set\" in results:\n",
    "        return list(set(entry[\"identifier\"].lower() for entry in results[\"result_set\"]))\n",
    "    else:\n",
    "        print(\"No results found in the response.\")\n",
    "        return []\n",
    "\n",
    "# Function to save PDB IDs to a CSV file\n",
    "def save_pdb_ids_to_csv(pdb_ids, filename='pdb_ids.csv'):\n",
    "    sorted_pdb_ids = sorted(pdb_ids)\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for pdb_id in sorted_pdb_ids:\n",
    "            writer.writerow([pdb_id])\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # File path to the txt file containing UniProt IDs\n",
    "    uniprot_file = \"uniprot_ids_human.txt\"\n",
    "\n",
    "    # Read UniProt IDs from the file\n",
    "    uniprot_ids = read_uniprot_ids_from_file(uniprot_file)\n",
    "\n",
    "    # Retrieve sequences for each UniProt ID\n",
    "    sequences = [get_canonical_sequence(uniprot_id) for uniprot_id in uniprot_ids if get_canonical_sequence(uniprot_id)]\n",
    "\n",
    "    # Perform PDB BLAST search if sequences are available\n",
    "    pdb_ids_from_blast = []\n",
    "    if sequences:\n",
    "        pdb_query = create_pdb_blast_query(sequences)\n",
    "        results = perform_pdb_blast_search(pdb_query)\n",
    "        if results:\n",
    "            pdb_ids_from_blast = extract_pdb_ids_from_results(results)\n",
    "\n",
    "    # Fetch PDB IDs by PFAM accession\n",
    "    pfam_accession = \"PF00048\"\n",
    "    pdb_ids_from_pfam = fetch_pdb_ids_by_pfam(pfam_accession)\n",
    "\n",
    "    # Combine and deduplicate PDB IDs\n",
    "    combined_pdb_ids = list(set(pdb_ids_from_blast + pdb_ids_from_pfam))\n",
    "\n",
    "    # Save the combined PDB IDs to a CSV file\n",
    "    save_pdb_ids_to_csv(combined_pdb_ids)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Number of unique PDB IDs found: {len(combined_pdb_ids)}\")\n",
    "    print(\"Combined PDB IDs have been saved to 'pdb_ids.csv'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f91ca7b-4a18-4d1b-8f2b-4d12d8d13384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to pdb_ids_with_details.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Function to get the entry name and organism type for a PDB ID\n",
    "def get_pdb_entry_details(pdb_id):\n",
    "    url = f\"https://data.rcsb.org/rest/v1/core/entry/{pdb_id}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract the entry name (title)\n",
    "        entry_name = data['struct']['title'] if 'struct' in data and 'title' in data['struct'] else \"Unknown\"\n",
    "\n",
    "        # Extract the organism scientific name (taxonomic information)\n",
    "        organism = \"Unknown\"\n",
    "        if 'rcsb_entity_source_organism' in data['rcsb_entry_container_identifiers']:\n",
    "            organism_info = data['rcsb_entry_container_identifiers']['rcsb_entity_source_organism']\n",
    "            if organism_info and 'scientific_name' in organism_info[0]:\n",
    "                organism = organism_info[0]['scientific_name']\n",
    "\n",
    "        return entry_name, organism\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for PDB ID: {pdb_id}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to update CSV with PDB entry names and organism types\n",
    "def add_pdb_entry_details_to_csv(input_csv, output_csv):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Ensure the file contains a column named \"PDB_ID\" (adjust if needed)\n",
    "    if 'identifier' not in df.columns:\n",
    "        print(f\"The file '{input_csv}' does not contain a 'PDB_ID' column.\")\n",
    "        return\n",
    "\n",
    "    # Initialize empty columns for Entry Name and Organism\n",
    "    df['Entry_Name'] = None\n",
    "    df['Organism_Type'] = None\n",
    "\n",
    "    # For each PDB ID, fetch the details and update the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        pdb_id = row['identifier']\n",
    "        entry_name, organism_type = get_pdb_entry_details(pdb_id)\n",
    "        df.at[index, 'Entry_Name'] = entry_name\n",
    "        df.at[index, 'Organism_Type'] = organism_type\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Updated CSV saved to {output_csv}\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Input and output CSV file paths\n",
    "    input_csv = 'pdb_blast_results.csv'  # Input CSV with PDB IDs\n",
    "    output_csv = 'pdb_ids_with_details.csv'  # Output CSV with added entry names and organism types\n",
    "\n",
    "    # Update the CSV with PDB entry names and organism types\n",
    "    add_pdb_entry_details_to_csv(input_csv, output_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemopardb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
